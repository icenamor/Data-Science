# -*- coding: utf-8 -*-
"""Clasificacion.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K-dcGVsGB6zZagoPu1eeABT0zZND0vTs

# Clasificación

# Datasets


*   https://www.kaggle.com/datasets
*   https://datasetsearch.research.google.com/
*  https://archive.ics.uci.edu/ml/datasets.php

Leer archivo del conjunto de datos del iris de la URL de la página web de la UCI Machine Learning.
"""

from urllib.request import urlretrieve

"""Importar pandas"""

import pandas as pd

"""Importar numpy"""

import numpy as np

"""# Importar un fichero de un repositorio

Localización de un fichero de datos
"""

iris = 'http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'

"""Guardar el fichero"""

urlretrieve(iris)

"""Lee el archivo en un DataFrame, donde el criterio de separación es la coma (,) y indicando que la primera linea no es la cabecera.
https://archive.ics.uci.edu/ml/datasets/Iris
"""



df = pd.read_csv(iris,  header=None, sep=',')

"""Añadir los nombres de las columnas de datos"""

attributes = ["sepal_length", "sepal_width", "petal_length", "petal_width", "class"]
df.columns = attributes

"""# Visualización de la cabecera, últimas filas y/o columnas

Ver el nombre de las columnas y las 5 primeras líneas de datos
"""

df.head()

"""Imprimir los últimos elementos de datos"""

df.tail()

"""Imprimir datos de una columna"""

df["sepal_length"]

df.sepal_length

"""#scikitlearn

Importar Algoritmos de clasificación
"""

from sklearn.tree import DecisionTreeClassifier

"""Parametros del árbol de decisión:
`class sklearn.tree.DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort='deprecated', ccp_alpha=0.0)[source]`


*   criterion{“gini”, “entropy”}, default=”gini”
*   splitter{“best”, “random”}, default=”best”
*   random_state int or RandomState, default=None
*   min_samples_split: int or float, default=2 [El número mínimo de muestras necesarias para dividir un nodo interno]

Vamos a imprimir las características de entrada
"""

features = list(df.columns[:4])

print("* features:", features, sep="\n")

"""Vamos a imprimir las clases que tenemos para nuestro modelo"""

print("* iris types:", df["class"].unique(), sep="\n")

"""# Modificación de datos entrada / salida

Vamos a introducir una clase numérica equivalente al valor nominal -> **target**
"""

df_mod = df.copy()
targets = df_mod["class"].unique()
map_to_int = {name: n for n, name in enumerate(targets)}
df_mod["target"] = df_mod["class"].replace(map_to_int)

"""Imprimimos el principio de la lista y del final para comprobar que esta este atributo nuevo"""

print("* df2.head()", df_mod[["target", "class"]].head(),
      sep="\n", end="\n\n")
print("* df_mod.tail()", df_mod[["target", "class"]].tail(),
      sep="\n", end="\n\n")
print("* targets", targets, sep="\n", end="\n\n")

"""Ahora podemos generar el árbol de decisión, usando el Clasificador de Árbol de Decisión importado anteriormente"""

y = df_mod["target"]
X = df_mod[features]
dt = DecisionTreeClassifier(min_samples_split=20, random_state=99)
dt.fit(X, y)

"""Extraemos los datos X e Y del marco de datos usando una simple indexación.
El árbol de decisión se inicializa con dos parámetros: 


1.   min_samples_split=20 requiere 20 muestras en un nodo para que se divida.
2.   random_state=99 para la semilla aleatoria.

# Visualización del árbol
"""

from sklearn import tree
tree.plot_tree(dt)

"""También podemos exportar el árbol en formato Graphviz utilizando  export_graphviz. Si se utiliza el gestor de paquetes conda, los binarios de graphviz"""

import graphviz

dot_data = tree.export_graphviz(dt, out_file=None, feature_names=features,  class_names=targets, filled=True, rounded=True,  special_characters=True)  
graph = graphviz.Source(dot_data)  
graph

"""Construir un informe de texto que muestre las reglas de un árbol de decisión."""

from sklearn.tree.export import export_text

r = export_text(dt, feature_names=features)

print(r)

"""#Validación split

Importar la libreria para dividir el conjunto de entrenamiento  y de test
"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
...     X, y, test_size=0.4, random_state=0)

"""Vamos a monstar los ejemplos de entrenamiento"""

X_train.shape, y_train.shape

"""Vamos a mostrar los ejemplos de test"""

X_test.shape, y_test.shape

"""Creamos el modelo con el conjunto de test"""

clf = DecisionTreeClassifier(min_samples_split=20, random_state=99).fit(X_train, y_train)

"""Evaluamos el modelo con los datos de test"""

clf.score(X_test, y_test)

"""#Validación cruzada"""

from sklearn.model_selection import cross_val_score

"""Hacemos la evaluación con folds=10"""

scores = cross_val_score(clf, X, y, cv=10)

"""Imprimimos la precisión"""

print("Precisión: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

"""También es posible utilizar otras estrategias de validación cruzada."""

from sklearn.model_selection import ShuffleSplit

n_samples = X.shape[0]
cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)
cross_val_score(clf, X, y, cv=cv)

"""# Balanceo de clases"""

df_mod['class'].value_counts()['Iris-setosa']

df_mod['class'].value_counts()['Iris-versicolor']

df_mod['class'].value_counts()['Iris-virginica']

"""##Cambiamos de dataset"""

df_train = pd.read_csv('badges.csv')
target_count = df_train.clase.value_counts()
print('Clase 0:', target_count[0])
print('Clase 1:', target_count[1])
print('Proportion:', round(target_count[0] / target_count[1], 2), ': 1')

target_count.plot(kind='bar', title='Cantidad (clase)');

from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Remove 'id' and 'target' columns
labels = df_train.columns[1:-1]

X = df_train[labels]
y = df_train['clase']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)

model = DecisionTreeClassifier(min_samples_split=20, random_state=99)
##model = XGBClassifier()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print("Precisión: %.2f%%" % (accuracy * 100.0))

df_train.head()

balanced = tree.export_graphviz(model, out_file=None, feature_names=labels,  class_names='clase', filled=True, rounded=True,  special_characters=True)  
graph = graphviz.Source(balanced)  
graph

"""## Matriz de confusion
Una forma interesante de evaluar los resultados es mediante una matriz de confusión, que muestra las predicciones correctas e incorrectas para cada clase. En la primera fila, la primera columna indica cuántas clases 0 se predijeron correctamente, y la segunda columna, cuántas clases 0 se predijeron como 1. En la segunda fila, observamos que todas las entradas de la clase 1 se predijeron erróneamente como clase 0.

Por lo tanto, cuanto más altos sean los valores diagonales de la matriz de confusión, mejor, indicando muchas predicciones correctas.
"""

from sklearn.metrics import confusion_matrix
from matplotlib import pyplot as plt

conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)
print('Confusion matrix:\n', conf_mat)

labels = ['Class 0', 'Class 1']
fig = plt.figure()
ax = fig.add_subplot(111)
cax = ax.matshow(conf_mat, cmap=plt.cm.Blues)
fig.colorbar(cax)
ax.set_xticklabels([''] + labels)
ax.set_yticklabels([''] + labels)
plt.xlabel('Predecido')
plt.ylabel('Esperado')
plt.show()

"""##Resampling
Una técnica ampliamente adoptada para tratar conjuntos de datos muy desequilibrados se denomina remuestreo. Consiste en retirar muestras de la clase mayoritaria (submuestreo) y/o añadir más ejemplos de la clase minoritaria (sobremuestreo).

A pesar de la ventaja de equilibrar las clases, estas técnicas también tienen sus puntos débiles (no hay almuerzo gratis). La implementación más simple del sobre-muestreo es duplicar los registros aleatorios de la clase minoritaria, lo que puede causar un sobreajuste. En el submuestreo, la técnica más simple consiste en eliminar los registros aleatorios de la clase mayoritaria, lo que puede causar la pérdida de información.
"""

# Class count
count_class_0, count_class_1 = df_train.clase.value_counts()

# Divide by class
df_class_0 = df_train[df_train['clase'] == '-']
df_class_1 = df_train[df_train['clase'] == '+']

df_class_0_under = df_class_0.sample(count_class_1)
df_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)

print('Resampling:')
print(df_test_under.clase.value_counts())

df_test_under.clase.value_counts().plot(kind='bar', title='cantidad (clase)');

df_test_under.info()

# Remove 'id' and 'target' columns
labels = df_test_under.columns[1:-1]

X = df_test_under[labels]
y = df_test_under['clase']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)

model = DecisionTreeClassifier(min_samples_split=20, random_state=99)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)
print('Confusion matrix:\n', conf_mat)

labels = ['Class 0', 'Class 1']
fig = plt.figure()
ax = fig.add_subplot(111)
cax = ax.matshow(conf_mat, cmap=plt.cm.Blues)
fig.colorbar(cax)
ax.set_xticklabels([''] + labels)
ax.set_yticklabels([''] + labels)
plt.xlabel('Predecido')
plt.ylabel('Esperado')
plt.show()

"""#Preguntas


1.   ¿Cómo cambias el citerio del árbol a entropia? ¿El resultado es distinto?
2.   ¿Cómo cambias el experimento para ejecutar el algoritmo de clasificación?

# Páginas webs
* https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html
* http://www.graphviz.org/
* https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score
"""