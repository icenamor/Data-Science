# -*- coding: utf-8 -*-
"""Regresión.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mAz3D_pTuv2DCYkCTbeSEtyifGo-SGrD

#Regresión
 Tenemos que cambiar el dataset porque la clase no es un nominal sino un valor númerico. 
 Sin embargo, no solo podemos importar un ejemplo, sino que podemos crear datos propios.
"""

import numpy as np
import matplotlib.pyplot as plt

"""Creamos un dataset"""

rng = np.random.RandomState(1)
X = np.linspace(0, 5, 120)[:, np.newaxis]
y = np.sin(X).ravel() + np.sin(6 * X).ravel() + rng.normal(0, 0.1, X.shape[0])

"""Importamos modelos de regresión"""

from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import AdaBoostRegressor

"""Inicializamos los modelos de regresión:


1.   DecisionTreeRegressor:
> max_depth  int, default=None 
> n_estimators 
> random_state int default=None, este valor se usa comosemilla utilizada por el generador de números aleatorios; 
2.   AdaBoostRegressor
> base_estimator (default=None)
El estimador de base. Si no hay ninguno, se usa DecisionTreeRegressor(max_depth=3).
"""

regresion_1 = DecisionTreeRegressor(max_depth=4)

regresion_2 = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4),
                          n_estimators=500, random_state=rng)

regresion_1.fit(X, y)
regresion_2.fit(X, y)

"""Utilizar el algoritmo de predicción"""

y_1 = regresion_1.predict(X)
y_2 = regresion_2.predict(X)

"""##Imprimir los resultados"""

X

y

plt.figure()
plt.scatter(X, y, c="k", label="Ejemplos de entrenamiento")
plt.plot(X, y_1, c="g", label="1 estimador", linewidth=2)
plt.plot(X, y_2, c="r", label="500 estimarores", linewidth=2)
plt.xlabel("datos")
plt.ylabel("objetivo")
plt.title("Regresión de árboles de decisión")
plt.legend()
plt.show()

"""##Imprimidir datos estadísticos"""

import statsmodels.api as statsmodels

"""Vamos a mostrar  el coeficiente de determinación R^2 de la predicción. Este coeficiente determina la calidad del modelo para replicar los resultados, y la proporción de variación de los resultados que puede explicarse por el modelo."""

regresion_1.score(X, y)

"""Comparamos el resultado con el modelo predictivo 2."""

regresion_2.score(X, y)

"""## statsmodels
El API se centra en los modelos y las pruebas estadísticas más utilizadas, y en las herramientas.
"""

import statsmodels.api as statsmodels

"""Regresión



1.   OLS (Odinary Least Squares)
1.   GLS (Generalized Least Squares)
2.   WLS (Weighted Least Squares)
"""

# Note the difference in argument order
model = statsmodels.OLS(y, X).fit()
predictions = model.predict(X) # make the predictions by the model

# Print out the statistics
model.summary()

"""# Ejercicio de regresión a partir de un conjunto de datos  y análisis de los datos de entrada

Vamos a cargar dos ficheros de datos, uno para entrenamiento y otro para test
"""

training = pd.read_csv('adult-data.csv') 
test = pd.read_csv('adult-test.csv')

"""Vamos a ojear la información que tenemos en los dos ficheros"""

training.head()

# libraries import
import pandas as pd
import numpy as np
from sklearn import preprocessing
from sklearn.model_selection import KFold
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt

training.shape

"""Datos de test"""

test.shape

test.dtypes

test.tail()

"""Vamos a comprobar si hay algún dato nulo"""

test.isnull().values.any()

training.info()

training.sex.nunique()

training.sex.unique()

"""Vamos a mostrar un histograma con los datos de entrenamiento"""

training.hist()

"""#Análisis de datos

##Relacion entre horas trabajadas y salario
"""

# Scatter plot of Height and Weight

ax1= training[training['sex']=='Male'].plot(kind='scatter', x='hours-per-week',y='salary', color='blue',alpha=0.5, figsize=(10,7))
training[training['sex']=='Female'].plot(kind='scatter', x='hours-per-week',y='salary', color='magenta',alpha=0.5, figsize=(10,7),ax=ax1)
plt.legend(labels=['Hombres','Mujeres'])
plt.title('Relación entre horas trabajadas y salario ', size=24)
plt.xlabel('Horas', size=18)
plt.ylabel('Salario', size=18);

import matplotlib.pyplot as plt
plt.style.use('ggplot')

# Histogram of the height
training.age.plot(kind='hist',color='purple',edgecolor='black',figsize=(10,7))
plt.title('Distribución de edad', size=24)
plt.xlabel('Edad', size=18)
plt.ylabel('Frecuencia', size=18)

"""Distrubución de la edad  y género"""

training[training['sex']=='Male'].age.plot(kind='hist',color='blue',edgecolor='black',alpha=0.5,figsize=(10,7))
training[training['sex']=='Female'].age.plot(kind='hist',color='magenta',edgecolor='black',alpha=0.5,figsize=(10,7))
plt.legend(labels=['Hombres','Mujeres'])
plt.title('Distribución por Edad', size=24)
plt.xlabel('Edad', size=18)
plt.ylabel('Frecuencia', size=18);

"""Los gráficos anteriores muestran la edad  para hombres y mujeres. Aunque el promedio de ambas distribuciones es mayor para los hombres, las distribuciones es similar para ambos géneros. Pandas proporciona un método llamado describir para describir las  estadísticas (tendencia central, dispersión y forma)."""

# Descriptive statistics male
statistics_male = training[training['sex']=='Male'].describe()
statistics_male.rename(columns=lambda x:x+'_male',inplace=True)

# Descriptive statistics female
statistics_female = training[training['sex']=='Female'].describe()
statistics_female.rename(columns=lambda x:x+'_female',inplace=True)

# Dataframe that contains statistics for both male and female
statistics = pd.concat([statistics_male,statistics_female], axis=1)
statistics

"""##Relación entre edad y salario"""

#Scatter plot of 500 females

sample_females = training[training['sex']=='Female'].sample(100)
sample_females.plot(kind='scatter', x='age',y='salary', color='magenta',alpha=0.5, figsize=(10,7))
plt.legend(labels=['Mujeres'])
plt.title('Relacion entre edad y salario (100 ejemplos)', size=20)
plt.xlabel('Edad', size=18)
plt.ylabel('Salario', size=18);

"""Vamos a predecir con una regresión lineal el salario con el atributo de la edad.
Además esto lo vamos a dividir por género para ver la brecha salarial de nuestro conjunto de datos
"""

# Hombres y mujeres dataframes.

df_males = training[training['sex']=='Male']
df_females = training[training['sex']=='Female']

hombres_1 = LinearRegression()

mujeres_1 = LinearRegression()

li = np.array(df_males.age)
li = li.reshape(-1, 1)
hombres_1.fit(li,df_males.salary)
h_1 = hombres_1.predict(li)


mi = np.array(df_females.age)
mi = mi.reshape(-1, 1)
mujeres_1.fit(mi,df_females.salary)
m_1 = mujeres_1.predict(mi)

#Scatter plots and regression lines.


# Scatter plots.
ax1= df_males.plot(kind='scatter', x='age',y='salary', color='blue')
df_females.plot(kind='scatter', x='age',y='salary', color='magenta',ax=ax1)

# Regression lines.
plt.plot(df_males.age,h_1, color='darkblue', linewidth=2)
plt.plot(df_females.age,m_1, color='deeppink', linewidth=2)

# Regression equations.
#plt.text(65,230,'y={:.2f}+{:.2f}*x'.format(male_fit[1],male_fit[0]),color='darkblue',size=12)
##plt.text(70,130,'y={:.2f}+{:.2f}*x'.format(female_fit[1],female_fit[0]),color='deeppink',size=12)

# Legend, title and labels.
plt.legend(labels=['Recta regresión Hombres','Recta regresión Mujeres', 'Hombres','Mujeres'])
plt.title('Relación entre edad y salario', size=24)
plt.xlabel('Edad (años)', size=18)
plt.ylabel('Salario (dolares)', size=18);

"""## Resultados con el test set"""

from sklearn.model_selection import train_test_split
features = list(training.columns[:14])
features

y = training["salary"]
X = training[features]
regresion_3 = DecisionTreeRegressor(max_depth=4)

regresion_4 = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4),
                          n_estimators=300, random_state=rng)
regresion_3.fit(X, y)
regresion_4.fit(X, y)

"""**Problema**"""

training.workclass.unique()

##training['workclass'] = pd.to_numeric(training['workclass'],errors='coerce')
##training['workclass']

df_training = training.copy()
targets = df_training["workclass"].unique()
map_to_int = {name: n for n, name in enumerate(targets)}
df_training["workclass"] = df_training["workclass"].replace(map_to_int)

df_training.workclass.unique()

targets = df_training["education"].unique()
map_to_int = {name: n for n, name in enumerate(targets)}
df_training["education"] = df_training["education"].replace(map_to_int)
df_training.education.unique()

targets = df_training[" marital-status"].unique()
map_to_int = {name: n for n, name in enumerate(targets)}
df_training[" marital-status"] = df_training[" marital-status"].replace(map_to_int)
df_training[" marital-status"].unique()

targets = df_training["occupation"].unique()
map_to_int = {name: n for n, name in enumerate(targets)}
df_training["occupation"] = df_training["occupation"].replace(map_to_int)
df_training.occupation.unique()

targets = df_training["relationship"].unique()
map_to_int = {name: n for n, name in enumerate(targets)}
df_training["relationship"] = df_training["relationship"].replace(map_to_int)
df_training.relationship.unique()

targets = df_training["race"].unique()
map_to_int = {name: n for n, name in enumerate(targets)}
df_training["race"] = df_training["race"].replace(map_to_int)
df_training.race.unique()

targets = df_training["sex"].unique()
map_to_int = {name: n for n, name in enumerate(targets)}
df_training["sex"] = df_training["sex"].replace(map_to_int)
df_training.sex.unique()

df_training.info()

"""Cambiarlo también en el test set"""

def_test = test.copy()
test.workclass.unique()

df_test = test.copy()
targets = df_test["workclass"].unique()
map_to_int = {name: n for n, name in enumerate(targets)}
df_test["workclass"] = df_test["workclass"].replace(map_to_int)

df_test.workclass.unique()


test.education.unique()
targets = df_test["education"].unique()
map_to_int = {name: n for n, name in enumerate(targets)}
df_test["education"] = df_test["education"].replace(map_to_int)
df_test.education.unique()


test[" marital-status"].unique()

targets = df_test[" marital-status"].unique()
map_to_int = {name: n for n, name in enumerate(targets)}
df_test[" marital-status"] = df_test[" marital-status"].replace(map_to_int)
df_test[" marital-status"].unique()

test.occupation.unique()
targets = df_test["occupation"].unique()
map_to_int = {name: n for n, name in enumerate(targets)}
df_test["occupation"] = df_test["occupation"].replace(map_to_int)
df_test.occupation.unique()

test.relationship.unique()
targets = df_test["relationship"].unique()
map_to_int = {name: n for n, name in enumerate(targets)}
df_test["relationship"] = df_test["relationship"].replace(map_to_int)
df_test.relationship.unique()

test.race.unique()
targets = df_test["race"].unique()
map_to_int = {name: n for n, name in enumerate(targets)}
df_test["race"] = df_test["race"].replace(map_to_int)
df_test.race.unique()

test.sex.unique()
targets = df_test["sex"].unique()
map_to_int = {name: n for n, name in enumerate(targets)}
df_test["sex"] = df_test["sex"].replace(map_to_int)
df_test.sex.unique()


df_test.info()

from sklearn import svm
features = list(df_training.columns[:14])
y = df_training["salary"]
X = df_training[features]
##(kernel='poly', C=100, gamma='auto', degree=3, epsilon=.1, coef0=1)
##(kernel='rbf', C=100, gamma=0.1, epsilon=.1)
regresion_3 = svm.SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)
predictions_3 = regresion_3.fit(X, y)

X_t = def_test[features]
y_t = df_test["salary"]
y_1 = regresion_3.predict(df_test[features])

X_t.shape

plt.figure()
plt.scatter(X.age, y, c="k", label="ejemplos entrenamiento")
plt.scatter(X_t.age, y_t, c="b", label="ejemplos test")
plt.plot(X_t.age, y_1, c="r", label="SVC", linewidth=2)
plt.xlabel("edad")
plt.ylabel("salario")

plt.title("Comparación de datos de entrenamiento  y de test")
plt.legend()
plt.show()

model = statsmodels.OLS(y, X).fit()
predictions_3 = model.predict(X) 
 
print_model = model.summary()
print(print_model)

"""#Páginas Webs


1.   https://www.statsmodels.org/stable/api.html
2. https://towardsdatascience.com/simple-and-multiple-linear-regression-with-python-c9ab422ec29c

3. https://riptutorial.com/es/machine-learning/topic/6156/scikit-learn
"""